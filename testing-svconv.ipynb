{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (1, 5, 5)\n",
    "spatial_scalars = np.zeros([2, 5, 5])\n",
    "spatial_scalars[0][0][0] = 1\n",
    "spatial_scalars[0][2][1] = 1\n",
    "spatial_scalars[0][2][3] = 0.67\n",
    "spatial_scalars[1][0][0] = 1\n",
    "spatial_scalars[1][2][1] = 0.67\n",
    "spatial_scalars[1][2][3] = 1\n",
    "print(spatial_scalars)\n",
    "input = np.array([\n",
    "    [[0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "     [0.6, 0.9, 0.6, 0.9, 0.6],\n",
    "     [0.9, 0.0, 0.9, 0.0, 0.9],\n",
    "     [0.6, 0.9, 0.6, 0.9, 0.6],\n",
    "     [0.1, 0.2, 0.3, 0.4, 0.5]]\n",
    "    ])\n",
    "filters = np.random.random((2, 3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"spatial_scalars:\\n\", spatial_scalars)\n",
    "print(\"input:\\n\", input)\n",
    "print(\"convolutional filters:\\n\", filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simply applies convolutional filter and returns the inner product\n",
    "def filter_pass(domain, x, y, filter):\n",
    "    acc = 0 # bias put here as a f(filter, x, y)\n",
    "    offset = (filter.shape[1]//2) # assume conv filters are square\n",
    "    for dx in range(-offset, offset + 1):\n",
    "        for dy in range(-offset, offset + 1):\n",
    "            acc += domain[0][(x + dx) % domain.shape[1]][(y + dy) % domain.shape[2]] * filter[dx + offset][dy + offset]\n",
    "    return acc\n",
    "\n",
    "\n",
    "## Spatially variant scalar convolution operation, wrap around, no bias\n",
    "def svconv2d_filter(input, filter, spatial_scalars):\n",
    "    ret = np.empty(shape=input.shape)\n",
    "    for x in range(input.shape[1]):\n",
    "        for y in range(input.shape[2]):\n",
    "            # 0 here for now because we only are trying this out on 1 channel, will iterate over all channels when time comes.\n",
    "            ret[0][x][y] = spatial_scalars[x][y] * filter_pass(input, x, y, filter)\n",
    "    return ret\n",
    "\n",
    "def svconv2d(input, filters, spatial_scalars):\n",
    "    return np.array([svconv2d_filter(input, filter=filters[i], spatial_scalars=spatial_scalars[i]) for i in range(filters.shape[0])])\n",
    "\n",
    "# after = svconv2d_filter(input, filters[0], spatial_scalars[0])\n",
    "print('input:\\n', input)\n",
    "print('after:\\n', svconv2d(input, filters, spatial_scalars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1.83395446/2.73724546"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 28, 28])\n",
      "torch.Size([1, 2, 30, 30])\n"
     ]
    }
   ],
   "source": [
    "## Circular padding:\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "input = torch.ones((1, 2, 28, 28))\n",
    "print(input.shape)\n",
    "print(F.pad(input, (1,1,1,1),\"circular\").shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[5.4677, 5.4688, 5.0508],\n",
      "          [5.1264, 5.1185, 5.0882],\n",
      "          [5.0289, 5.3090, 5.2771]]]])\n",
      "torch.Size([1, 1, 3, 3])\n",
      "torch.Size([1, 1, 3, 3])\n",
      "tensor([[[[2.0618, 2.4289, 1.8683],\n",
      "          [2.2202, 2.2237, 2.0290],\n",
      "          [2.2045, 2.1236, 2.3801]],\n",
      "\n",
      "         [[3.4059, 3.0399, 3.1825],\n",
      "          [2.9062, 2.8948, 3.0592],\n",
      "          [2.8244, 3.1853, 2.8970]]]])\n"
     ]
    }
   ],
   "source": [
    "inpt = torch.rand(1, 2, 3, 3)\n",
    "a = F.pad(inpt, (1, 1, 1, 1), mode='circular')\n",
    "conv = torch.rand(1, 2, 3, 3)\n",
    "\n",
    "spatial_scalars = torch.zeros(2, 3, 3)\n",
    "\n",
    "print(F.conv2d(a, conv))\n",
    "\n",
    "output = torch.zeros(inpt.shape)\n",
    "for chan in range(a.shape[1]):\n",
    "    intermed = F.conv2d(a[:,chan:chan+1,:,:], conv[:,chan:chan+1,:,:])\n",
    "    print(intermed.shape)\n",
    "    output[:,chan:chan+1,:,:] += intermed\n",
    "print(output)\n",
    "assert not (torch.isclose(output[:,0,:,:] + output[:,1,:,:], F.conv2d(a, conv)).__contains__(False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[5, 7],\n",
      "          [7, 6]],\n",
      "\n",
      "         [[5, 2],\n",
      "          [8, 4]]]])\n",
      "tensor([[[[0., 0.],\n",
      "          [1., 0.]],\n",
      "\n",
      "         [[0., 0.],\n",
      "          [3., 0.]]]])\n",
      "tensor([[[ 0.,  0.],\n",
      "         [31.,  0.]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randint(0, 9, (1, 2, 2, 2))\n",
    "print(x)\n",
    "a = torch.zeros((1, 2, 2, 2))\n",
    "a[0][0][1][0] = 1\n",
    "a[0][1][1][0] = 3\n",
    "print(a)\n",
    "print((a * x).sum(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 2)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1, 1) + (2,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SVConv2d' object has no attribute 'spatial_scalars'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/jack/Repos/jack-champagne/p4m-wave-equation/scaled-spatial-conv/testing-svconv.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jack/Repos/jack-champagne/p4m-wave-equation/scaled-spatial-conv/testing-svconv.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfunctional\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mF\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jack/Repos/jack-champagne/p4m-wave-equation/scaled-spatial-conv/testing-svconv.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrand(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m3\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/jack/Repos/jack-champagne/p4m-wave-equation/scaled-spatial-conv/testing-svconv.ipynb#X12sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m convlayer \u001b[39m=\u001b[39m SVConv2d(in_channels\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, out_channels\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, kernel_size\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m, spatial_scalar_hint\u001b[39m=\u001b[39;49m\u001b[39minput\u001b[39;49m\u001b[39m.\u001b[39;49msize(), stride\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, padding\u001b[39m=\u001b[39;49m(\u001b[39m1\u001b[39;49m,\u001b[39m1\u001b[39;49m), padding_mode\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mcircular\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jack/Repos/jack-champagne/p4m-wave-equation/scaled-spatial-conv/testing-svconv.ipynb#X12sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m convlayer(\u001b[39minput\u001b[39m)\n",
      "File \u001b[0;32m~/Repos/jack-champagne/p4m-wave-equation/scaled-spatial-conv/svconv.py:289\u001b[0m, in \u001b[0;36mSVConv2d.__init__\u001b[0;34m(self, in_channels, out_channels, kernel_size, spatial_scalar_hint, stride, padding, dilation, groups, bias, padding_mode, device, dtype)\u001b[0m\n\u001b[1;32m    287\u001b[0m padding_ \u001b[39m=\u001b[39m padding \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(padding, \u001b[39mstr\u001b[39m) \u001b[39melse\u001b[39;00m _pair(padding)\n\u001b[1;32m    288\u001b[0m dilation_ \u001b[39m=\u001b[39m _pair(dilation)\n\u001b[0;32m--> 289\u001b[0m \u001b[39msuper\u001b[39;49m(SVConv2d, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[1;32m    290\u001b[0m     in_channels, out_channels, kernel_size_, stride_, padding_, dilation_, spatial_scalar_hint,\n\u001b[1;32m    291\u001b[0m     \u001b[39mFalse\u001b[39;49;00m, _pair(\u001b[39m0\u001b[39;49m), groups, bias, padding_mode, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfactory_kwargs)\n",
      "File \u001b[0;32m~/Repos/jack-champagne/p4m-wave-equation/scaled-spatial-conv/svconv.py:45\u001b[0m, in \u001b[0;36m_SVConvNd.__init__\u001b[0;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, spatial_scalar_hint, transposed, output_padding, groups, bias, padding_mode, device, dtype)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m     29\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     30\u001b[0m     in_channels: \u001b[39mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     42\u001b[0m     device\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     43\u001b[0m dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     44\u001b[0m     factory_kwargs \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mdevice\u001b[39m\u001b[39m'\u001b[39m: device, \u001b[39m'\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m'\u001b[39m: dtype}\n\u001b[0;32m---> 45\u001b[0m     \u001b[39msuper\u001b[39;49m(_SVConvNd, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(in_channels, out_channels, kernel_size, stride, padding, dilation,\n\u001b[1;32m     46\u001b[0m         \u001b[39mFalse\u001b[39;49;00m, _pair(\u001b[39m0\u001b[39;49m), groups, bias, padding_mode, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfactory_kwargs)\n\u001b[1;32m     47\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mspatial_scalars \u001b[39m=\u001b[39m Parameter(torch\u001b[39m.\u001b[39mempty(spatial_scalar_hint))\n\u001b[1;32m     48\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreset_parameters()\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch-devel/lib/python3.9/site-packages/torch/nn/modules/conv.py:138\u001b[0m, in \u001b[0;36m_ConvNd.__init__\u001b[0;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, bias, padding_mode, device, dtype)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    136\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mregister_parameter(\u001b[39m'\u001b[39m\u001b[39mbias\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m--> 138\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreset_parameters()\n",
      "File \u001b[0;32m~/Repos/jack-champagne/p4m-wave-equation/scaled-spatial-conv/svconv.py:60\u001b[0m, in \u001b[0;36m_SVConvNd.reset_parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     58\u001b[0m bound \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39m/\u001b[39m math\u001b[39m.\u001b[39msqrt(fan_in)\n\u001b[1;32m     59\u001b[0m init\u001b[39m.\u001b[39muniform_(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias, \u001b[39m-\u001b[39mbound, bound)\n\u001b[0;32m---> 60\u001b[0m init\u001b[39m.\u001b[39muniform_(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mspatial_scalars, \u001b[39m-\u001b[39mbound, bound)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch-devel/lib/python3.9/site-packages/torch/nn/modules/module.py:1177\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1175\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[1;32m   1176\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1177\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1178\u001b[0m     \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SVConv2d' object has no attribute 'spatial_scalars'"
     ]
    }
   ],
   "source": [
    "from svconv import SVConv2d\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "input = torch.rand(1, 2, 3, 3)\n",
    "\n",
    "convlayer = SVConv2d(in_channels=2, out_channels=2, kernel_size=3, spatial_scalar_hint=input.size(), stride=1, padding=(1,1), padding_mode='circular')\n",
    "convlayer(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('pytorch-devel')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "746d1c1fe05b765ee7ecaa8b421be9fa4f6134b00b1cddd46be87e0084c0c9b9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
