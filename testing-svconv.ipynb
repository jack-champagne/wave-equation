{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (1, 5, 5)\n",
    "spatial_scalars = np.zeros([2, 5, 5])\n",
    "spatial_scalars[0][0][0] = 1\n",
    "spatial_scalars[0][2][1] = 1\n",
    "spatial_scalars[0][2][3] = 0.67\n",
    "spatial_scalars[1][0][0] = 1\n",
    "spatial_scalars[1][2][1] = 0.67\n",
    "spatial_scalars[1][2][3] = 1\n",
    "print(spatial_scalars)\n",
    "input = np.array([\n",
    "    [[0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "     [0.6, 0.9, 0.6, 0.9, 0.6],\n",
    "     [0.9, 0.0, 0.9, 0.0, 0.9],\n",
    "     [0.6, 0.9, 0.6, 0.9, 0.6],\n",
    "     [0.1, 0.2, 0.3, 0.4, 0.5]]\n",
    "    ])\n",
    "filters = np.random.random((2, 3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"spatial_scalars:\\n\", spatial_scalars)\n",
    "print(\"input:\\n\", input)\n",
    "print(\"convolutional filters:\\n\", filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simply applies convolutional filter and returns the inner product\n",
    "def filter_pass(domain, x, y, filter):\n",
    "    acc = 0 # bias put here as a f(filter, x, y)\n",
    "    offset = (filter.shape[1]//2) # assume conv filters are square\n",
    "    for dx in range(-offset, offset + 1):\n",
    "        for dy in range(-offset, offset + 1):\n",
    "            acc += domain[0][(x + dx) % domain.shape[1]][(y + dy) % domain.shape[2]] * filter[dx + offset][dy + offset]\n",
    "    return acc\n",
    "\n",
    "\n",
    "## Spatially variant scalar convolution operation, wrap around, no bias\n",
    "def svconv2d_filter(input, filter, spatial_scalars):\n",
    "    ret = np.empty(shape=input.shape)\n",
    "    for x in range(input.shape[1]):\n",
    "        for y in range(input.shape[2]):\n",
    "            # 0 here for now because we only are trying this out on 1 channel, will iterate over all channels when time comes.\n",
    "            ret[0][x][y] = spatial_scalars[x][y] * filter_pass(input, x, y, filter)\n",
    "    return ret\n",
    "\n",
    "def svconv2d(input, filters, spatial_scalars):\n",
    "    return np.array([svconv2d_filter(input, filter=filters[i], spatial_scalars=spatial_scalars[i]) for i in range(filters.shape[0])])\n",
    "\n",
    "# after = svconv2d_filter(input, filters[0], spatial_scalars[0])\n",
    "print('input:\\n', input)\n",
    "print('after:\\n', svconv2d(input, filters, spatial_scalars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1.83395446/2.73724546"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 28, 28])\n",
      "torch.Size([1, 2, 30, 30])\n"
     ]
    }
   ],
   "source": [
    "## Circular padding:\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "input = torch.ones((1, 2, 28, 28))\n",
    "print(input.shape)\n",
    "print(F.pad(input, (1,1,1,1),\"circular\").shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[5.4677, 5.4688, 5.0508],\n",
      "          [5.1264, 5.1185, 5.0882],\n",
      "          [5.0289, 5.3090, 5.2771]]]])\n",
      "torch.Size([1, 1, 3, 3])\n",
      "torch.Size([1, 1, 3, 3])\n",
      "tensor([[[[2.0618, 2.4289, 1.8683],\n",
      "          [2.2202, 2.2237, 2.0290],\n",
      "          [2.2045, 2.1236, 2.3801]],\n",
      "\n",
      "         [[3.4059, 3.0399, 3.1825],\n",
      "          [2.9062, 2.8948, 3.0592],\n",
      "          [2.8244, 3.1853, 2.8970]]]])\n"
     ]
    }
   ],
   "source": [
    "inpt = torch.rand(1, 2, 3, 3)\n",
    "a = F.pad(inpt, (1, 1, 1, 1), mode='circular')\n",
    "conv = torch.rand(1, 2, 3, 3)\n",
    "\n",
    "spatial_scalars = torch.zeros(2, 3, 3)\n",
    "\n",
    "print(F.conv2d(a, conv))\n",
    "\n",
    "output = torch.zeros(inpt.shape)\n",
    "for chan in range(a.shape[1]):\n",
    "    intermed = F.conv2d(a[:,chan:chan+1,:,:], conv[:,chan:chan+1,:,:])\n",
    "    print(intermed.shape)\n",
    "    output[:,chan:chan+1,:,:] += intermed\n",
    "print(output)\n",
    "assert not (torch.isclose(output[:,0,:,:] + output[:,1,:,:], F.conv2d(a, conv)).__contains__(False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[5, 7],\n",
      "          [7, 6]],\n",
      "\n",
      "         [[5, 2],\n",
      "          [8, 4]]]])\n",
      "tensor([[[[0., 0.],\n",
      "          [1., 0.]],\n",
      "\n",
      "         [[0., 0.],\n",
      "          [3., 0.]]]])\n",
      "tensor([[[ 0.,  0.],\n",
      "         [31.,  0.]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randint(0, 9, (1, 2, 2, 2))\n",
    "print(x)\n",
    "a = torch.zeros((1, 2, 2, 2))\n",
    "a[0][0][1][0] = 1\n",
    "a[0][1][1][0] = 3\n",
    "print(a)\n",
    "print((a * x).sum(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 2)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1, 1) + (2,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected padding to be a single integer value or a list of 1 values to match the convolution dimensions, but got padding=[0, 0]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/jack/Repos/jack-champagne/p4m-wave-equation/scaled-spatial-conv/testing-svconv.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jack/Repos/jack-champagne/p4m-wave-equation/scaled-spatial-conv/testing-svconv.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrand(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m3\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jack/Repos/jack-champagne/p4m-wave-equation/scaled-spatial-conv/testing-svconv.ipynb#X12sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m convlayer \u001b[39m=\u001b[39m SVConv2d(in_channels\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, out_channels\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, kernel_size\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, spatial_scalar_hint\u001b[39m=\u001b[39m\u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize(), stride\u001b[39m=\u001b[39m(\u001b[39m1\u001b[39m,), padding\u001b[39m=\u001b[39m(\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m), padding_mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcircular\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/jack/Repos/jack-champagne/p4m-wave-equation/scaled-spatial-conv/testing-svconv.ipynb#X12sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m convlayer(\u001b[39minput\u001b[39;49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch-devel/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1103\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Repos/jack-champagne/p4m-wave-equation/scaled-spatial-conv/svconv.py:391\u001b[0m, in \u001b[0;36mSVConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 391\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mspatial_scalar, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/Repos/jack-champagne/p4m-wave-equation/scaled-spatial-conv/svconv.py:381\u001b[0m, in \u001b[0;36mSVConv2d._conv_forward\u001b[0;34m(self, input, spatial_scalar, weight, bias)\u001b[0m\n\u001b[1;32m    378\u001b[0m padded_input \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode)\n\u001b[1;32m    380\u001b[0m \u001b[39mfor\u001b[39;00m chan \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(padded_input\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]):\n\u001b[0;32m--> 381\u001b[0m     single_channel \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49mconv2d(padded_input[:,chan,:,:], weight[:,chan,:,:], bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride, _pair(\u001b[39m0\u001b[39;49m), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n\u001b[1;32m    382\u001b[0m     output[:,chan,:,:] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m spatial_scalar[chan] \u001b[39m*\u001b[39m single_channel\n\u001b[1;32m    384\u001b[0m intermediate \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mconv2d(padded_input, weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride, _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected padding to be a single integer value or a list of 1 values to match the convolution dimensions, but got padding=[0, 0]"
     ]
    }
   ],
   "source": [
    "from svconv import SVConv2d\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "input = torch.rand(1, 2, 3, 3)\n",
    "\n",
    "convlayer = SVConv2d(in_channels=2, out_channels=2, kernel_size=3, spatial_scalar_hint=input.size(), stride=(1,), padding=(1,1,1,1), padding_mode='circular')\n",
    "convlayer(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('pytorch-devel')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "746d1c1fe05b765ee7ecaa8b421be9fa4f6134b00b1cddd46be87e0084c0c9b9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
