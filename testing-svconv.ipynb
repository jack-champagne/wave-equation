{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.  ]\n",
      "  [0.   1.   0.   0.67 0.  ]\n",
      "  [0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.  ]]\n",
      "\n",
      " [[1.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.67 0.   1.   0.  ]\n",
      "  [0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.  ]]]\n",
      "12.9\n",
      "12.9\n"
     ]
    }
   ],
   "source": [
    "input_shape = (1, 5, 5)\n",
    "spatial_scalars = np.zeros([2, 5, 5])\n",
    "spatial_scalars[0][0][0] = 1\n",
    "spatial_scalars[0][2][1] = 1\n",
    "spatial_scalars[0][2][3] = 0.67\n",
    "spatial_scalars[1][0][0] = 1\n",
    "spatial_scalars[1][2][1] = 0.67\n",
    "spatial_scalars[1][2][3] = 1\n",
    "print(spatial_scalars)\n",
    "input = np.array([\n",
    "    [[0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "     [0.6, 0.9, 0.6, 0.9, 0.6],\n",
    "     [0.9, 0.0, 0.9, 0.0, 0.9],\n",
    "     [0.6, 0.9, 0.6, 0.9, 0.6],\n",
    "     [0.1, 0.2, 0.3, 0.4, 0.5]]\n",
    "    ])\n",
    "filters = np.random.random((2, 3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spatial_scalars:\n",
      " [[[1.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.  ]\n",
      "  [0.   1.   0.   0.67 0.  ]\n",
      "  [0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.  ]]\n",
      "\n",
      " [[1.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.67 0.   1.   0.  ]\n",
      "  [0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.  ]]]\n",
      "input:\n",
      " [[[0.1 0.2 0.3 0.4 0.5]\n",
      "  [0.6 0.9 0.6 0.9 0.6]\n",
      "  [0.9 0.  0.9 0.  0.9]\n",
      "  [0.6 0.9 0.6 0.9 0.6]\n",
      "  [0.1 0.2 0.3 0.4 0.5]]]\n",
      "convolutional filters:\n",
      " [[[0.02883418 0.45232376 0.94250214]\n",
      "  [0.99528437 0.77810749 0.73695356]\n",
      "  [0.73952314 0.3275751  0.28513554]]\n",
      "\n",
      " [[0.69069447 0.50452381 0.5487601 ]\n",
      "  [0.88158949 0.42305141 0.05459987]\n",
      "  [0.17279914 0.05083774 0.97796674]]]\n"
     ]
    }
   ],
   "source": [
    "print(\"spatial_scalars:\\n\", spatial_scalars)\n",
    "print(\"input:\\n\", input)\n",
    "print(\"convolutional filters:\\n\", filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:\n",
      " [[[0.1 0.2 0.3 0.4 0.5]\n",
      "  [0.6 0.9 0.6 0.9 0.6]\n",
      "  [0.9 0.  0.9 0.  0.9]\n",
      "  [0.6 0.9 0.6 0.9 0.6]\n",
      "  [0.1 0.2 0.3 0.4 0.5]]]\n",
      "after:\n",
      " [[[[1.86787447 0.         0.         0.         0.        ]\n",
      "   [0.         0.         0.         0.         0.        ]\n",
      "   [0.         3.45852012 0.         2.31720848 0.        ]\n",
      "   [0.         0.         0.         0.         0.        ]\n",
      "   [0.         0.         0.         0.         0.        ]]]\n",
      "\n",
      "\n",
      " [[[2.0139237  0.         0.         0.         0.        ]\n",
      "   [0.         0.         0.         0.         0.        ]\n",
      "   [0.         1.86027383 0.         2.7765281  0.        ]\n",
      "   [0.         0.         0.         0.         0.        ]\n",
      "   [0.         0.         0.         0.         0.        ]]]]\n"
     ]
    }
   ],
   "source": [
    "# Simply applies convolutional filter and returns the inner product\n",
    "def filter_pass(domain, x, y, filter):\n",
    "    acc = 0 # bias put here as a f(filter, x, y)\n",
    "    offset = (filter.shape[1]//2) # assume conv filters are square\n",
    "    for dx in range(-offset, offset + 1):\n",
    "        for dy in range(-offset, offset + 1):\n",
    "            acc += domain[0][(x + dx) % domain.shape[1]][(y + dy) % domain.shape[2]] * filter[dx + offset][dy + offset]\n",
    "    return acc\n",
    "\n",
    "\n",
    "## Spatially variant scalar convolution operation, wrap around, no bias\n",
    "def svconv2d_filter(input, filter, spatial_scalars):\n",
    "    ret = np.empty(shape=input.shape)\n",
    "    for x in range(input.shape[1]):\n",
    "        for y in range(input.shape[2]):\n",
    "            # 0 here for now because we only are trying this out on 1 channel, will iterate over all channels when time comes.\n",
    "            ret[0][x][y] = spatial_scalars[x][y] * filter_pass(input, x, y, filter)\n",
    "    return ret\n",
    "\n",
    "def svconv2d(input, filters, spatial_scalars):\n",
    "    return np.array([svconv2d_filter(input, filter=filters[i], spatial_scalars=spatial_scalars[i]) for i in range(filters.shape[0])])\n",
    "\n",
    "# after = svconv2d_filter(input, filters[0], spatial_scalars[0])\n",
    "print('input:\\n', input)\n",
    "print('after:\\n', svconv2d(input, filters, spatial_scalars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6700000006575954"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.83395446/2.73724546"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 28, 28])\n",
      "torch.Size([1, 2, 30, 30])\n"
     ]
    }
   ],
   "source": [
    "## Circular padding:\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "input = torch.ones((1, 2, 28, 28))\n",
    "print(input.shape)\n",
    "print(F.pad(input, (1,1,1,1),\"circular\").shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[2.2539, 2.2681, 2.3813],\n",
      "          [2.6034, 2.4541, 2.3977],\n",
      "          [2.2744, 2.1757, 2.3888]]]])\n",
      "tensor([[[[2.8652, 2.9157, 2.8558],\n",
      "          [2.7867, 2.8869, 2.5197],\n",
      "          [2.5025, 3.0357, 2.6416]]]])\n",
      "tensor([[[5.1191, 5.1838, 5.2371],\n",
      "         [5.3901, 5.3410, 4.9174],\n",
      "         [4.7769, 5.2114, 5.0305]]])\n",
      "tensor([[[[5.1191, 5.1838, 5.2371],\n",
      "          [5.3901, 5.3410, 4.9174],\n",
      "          [4.7769, 5.2114, 5.0305]]]])\n"
     ]
    }
   ],
   "source": [
    "inpt = torch.rand(1, 2, 3, 3)\n",
    "a = F.pad(inpt, (1, 1, 1, 1), mode='circular')\n",
    "conv = torch.rand(1, 2, 3, 3)\n",
    "\n",
    "spatial_scalars = torch.zeros(2, 3, 3)\n",
    "\n",
    "# print(F.conv2d(a, conv))\n",
    "\n",
    "output = torch.zeros(inpt.shape)\n",
    "for chan in range(a.shape[1]):\n",
    "    intermed = F.conv2d(a[:,chan:chan+1,:,:], conv[:,chan:chan+1,:,:])\n",
    "    print(intermed)\n",
    "    output[:,chan:chan+1,:,:] += 1 * intermed\n",
    "print(output[:,0,:,:] + output[:,1,:,:])\n",
    "print(F.conv2d(a, conv))\n",
    "assert not (torch.isclose(output[:,0,:,:] + output[:,1,:,:], F.conv2d(a, conv)).__contains__(False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[4, 2],\n",
      "          [3, 3]],\n",
      "\n",
      "         [[7, 8],\n",
      "          [3, 0]]]])\n",
      "tensor([[[[0., 0.],\n",
      "          [1., 0.]],\n",
      "\n",
      "         [[0., 0.],\n",
      "          [3., 0.]]]])\n",
      "tensor([[[ 0.,  0.],\n",
      "         [12.,  0.]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randint(0, 9, (1, 2, 2, 2))\n",
    "print(x)\n",
    "a = torch.zeros((1, 2, 2, 2))\n",
    "a[0][0][1][0] = 1\n",
    "a[0][1][1][0] = 3\n",
    "print(a)\n",
    "print((a * x).sum(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1, 1) + (2,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.1916, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[0.1755, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000]]]], grad_fn=<AddcmulBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from svconv import SVConv2d\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "input = torch.rand(1, 2, 3, 3)\n",
    "\n",
    "convlayer = SVConv2d(in_channels=2, out_channels=2, kernel_size=3, spatial_scalar_hint=input.size(), stride=1, padding=(1,1), padding_mode='circular')\n",
    "convlayer(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.8436, 0.4265, 0.9561],\n",
      "          [0.0770, 0.4108, 0.0014],\n",
      "          [0.5414, 0.6419, 0.2976]],\n",
      "\n",
      "         [[0.7077, 0.4189, 0.0655],\n",
      "          [0.8839, 0.8083, 0.7528],\n",
      "          [0.8988, 0.6839, 0.7658]]],\n",
      "\n",
      "\n",
      "        [[[0.9149, 0.3993, 0.1100],\n",
      "          [0.2541, 0.4333, 0.4451],\n",
      "          [0.4966, 0.7865, 0.6604]],\n",
      "\n",
      "         [[0.1303, 0.3498, 0.3824],\n",
      "          [0.8043, 0.3186, 0.2908],\n",
      "          [0.4196, 0.3728, 0.3769]]]])\n",
      "Parameter containing:\n",
      "tensor([[[[-0.2220, -0.0462, -0.1132],\n",
      "          [-0.0629, -0.2082,  0.0946],\n",
      "          [-0.2113, -0.0150,  0.0819]],\n",
      "\n",
      "         [[-0.0794,  0.1337,  0.0297],\n",
      "          [ 0.1296,  0.1512, -0.1041],\n",
      "          [ 0.0857, -0.1020,  0.0739]]],\n",
      "\n",
      "\n",
      "        [[[-0.1232,  0.1090,  0.0477],\n",
      "          [-0.0922, -0.1156,  0.0610],\n",
      "          [ 0.2199,  0.1131, -0.0228]],\n",
      "\n",
      "         [[-0.0114,  0.1340, -0.1638],\n",
      "          [ 0.0784, -0.0781,  0.1364],\n",
      "          [-0.0841,  0.0117,  0.0796]]]], requires_grad=True)\n",
      "tensor([[[[-0.1413, -0.0174, -0.3211],\n",
      "          [-0.0218, -0.2812, -0.1790],\n",
      "          [-0.0900, -0.0589,  0.0687]],\n",
      "\n",
      "         [[-0.0891, -0.0054,  0.0525],\n",
      "          [ 0.2488,  0.2581,  0.2572],\n",
      "          [ 0.3695,  0.1883,  0.1604]]]], grad_fn=<AddBackward0>)\n",
      "tensor([[[[-0.4441, -0.2598, -0.1204],\n",
      "          [-0.0938, -0.1651, -0.3753],\n",
      "          [-0.0217, -0.3870, -0.1969]],\n",
      "\n",
      "         [[ 0.1041,  0.0047,  0.1783],\n",
      "          [ 0.2068,  0.1325,  0.3112],\n",
      "          [ 0.1389,  0.2491, -0.0859]]]], grad_fn=<AddBackward0>)\n",
      "tensor([[[[-0.1413, -0.0174, -0.3211],\n",
      "          [-0.0218, -0.2812, -0.1790],\n",
      "          [-0.0900, -0.0589,  0.0687]],\n",
      "\n",
      "         [[-0.0891, -0.0054,  0.0525],\n",
      "          [ 0.2488,  0.2581,  0.2572],\n",
      "          [ 0.3695,  0.1883,  0.1604]]],\n",
      "\n",
      "\n",
      "        [[[-0.4441, -0.2598, -0.1204],\n",
      "          [-0.0938, -0.1651, -0.3753],\n",
      "          [-0.0217, -0.3870, -0.1969]],\n",
      "\n",
      "         [[ 0.1041,  0.0047,  0.1783],\n",
      "          [ 0.2068,  0.1325,  0.3112],\n",
      "          [ 0.1389,  0.2491, -0.0859]]]], grad_fn=<SlowConv2DBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "convlayer = nn.Conv2d(2, 2, 3, padding=(1,1), padding_mode='circular', bias=False)\n",
    "\n",
    "input = torch.rand(2, 2, 3, 3)\n",
    "\n",
    "padded_input = F.pad(input, convlayer._reversed_padding_repeated_twice, mode=convlayer.padding_mode)\n",
    "output = F.conv2d(padded_input, convlayer.weight, convlayer.bias, convlayer.stride, torch.nn.modules.utils._pair(0), convlayer.dilation, convlayer.groups)\n",
    "\n",
    "output11 = F.conv2d(padded_input[0:1,0:1,:,:], convlayer.weight[:,0:1,:,:], convlayer.bias, convlayer.stride, torch.nn.modules.utils._pair(0), convlayer.dilation, convlayer.groups)\n",
    "output12 = F.conv2d(padded_input[0:1,1:2,:,:], convlayer.weight[:,1:2,:,:], convlayer.bias, convlayer.stride, torch.nn.modules.utils._pair(0), convlayer.dilation, convlayer.groups)\n",
    "\n",
    "output21 = F.conv2d(padded_input[1:2,0:1,:,:], convlayer.weight[:,0:1,:,:], convlayer.bias, convlayer.stride, torch.nn.modules.utils._pair(0), convlayer.dilation, convlayer.groups)\n",
    "output22 = F.conv2d(padded_input[1:2,1:2,:,:], convlayer.weight[:,1:2,:,:], convlayer.bias, convlayer.stride, torch.nn.modules.utils._pair(0), convlayer.dilation, convlayer.groups)\n",
    "\n",
    "print(input)\n",
    "\n",
    "print(convlayer.weight)\n",
    "\n",
    "print(output11 + output12)\n",
    "print(output21 + output22)\n",
    "print(convlayer(input))\n",
    "\n",
    "# print(convlayer.weight)\n",
    "# print(convlayer.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.2976, 0.5414, 0.6419, 0.2976, 0.5414],\n",
      "          [0.9561, 0.8436, 0.4265, 0.9561, 0.8436],\n",
      "          [0.0014, 0.0770, 0.4108, 0.0014, 0.0770],\n",
      "          [0.2976, 0.5414, 0.6419, 0.2976, 0.5414],\n",
      "          [0.9561, 0.8436, 0.4265, 0.9561, 0.8436]],\n",
      "\n",
      "         [[0.7658, 0.8988, 0.6839, 0.7658, 0.8988],\n",
      "          [0.0655, 0.7077, 0.4189, 0.0655, 0.7077],\n",
      "          [0.7528, 0.8839, 0.8083, 0.7528, 0.8839],\n",
      "          [0.7658, 0.8988, 0.6839, 0.7658, 0.8988],\n",
      "          [0.0655, 0.7077, 0.4189, 0.0655, 0.7077]]],\n",
      "\n",
      "\n",
      "        [[[0.6604, 0.4966, 0.7865, 0.6604, 0.4966],\n",
      "          [0.1100, 0.9149, 0.3993, 0.1100, 0.9149],\n",
      "          [0.4451, 0.2541, 0.4333, 0.4451, 0.2541],\n",
      "          [0.6604, 0.4966, 0.7865, 0.6604, 0.4966],\n",
      "          [0.1100, 0.9149, 0.3993, 0.1100, 0.9149]],\n",
      "\n",
      "         [[0.3769, 0.4196, 0.3728, 0.3769, 0.4196],\n",
      "          [0.3824, 0.1303, 0.3498, 0.3824, 0.1303],\n",
      "          [0.2908, 0.8043, 0.3186, 0.2908, 0.8043],\n",
      "          [0.3769, 0.4196, 0.3728, 0.3769, 0.4196],\n",
      "          [0.3824, 0.1303, 0.3498, 0.3824, 0.1303]]]])\n"
     ]
    }
   ],
   "source": [
    "print(padded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor, tensor\n",
    "\n",
    "def compute_cross_corr(t1: Tensor, t2: Tensor):\n",
    "    assert t1.numel() == t2.numel(), \"{} {} dimension do not match\".format(t1.shape, t2.shape)\n",
    "    a = torch.mul(t1, t2)\n",
    "    return torch.sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.3270, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_cross_corr(padded_input[0:1,0:1,0:3,0:3], convlayer.weight[0:1,0:1,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.5070, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(compute_cross_corr(padded_input[0:1,1:2,0:3,0:3], convlayer.weight[0:1,0:1,:,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.7658, 0.8988, 0.6839],\n",
       "          [0.0655, 0.7077, 0.4189],\n",
       "          [0.7528, 0.8839, 0.8083]]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-0.1070\n",
    "padded_input[0:1,1:2,0:3,0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.9149]],\n",
      "\n",
      "         [[0.3993]]],\n",
      "\n",
      "\n",
      "        [[[0.1100]],\n",
      "\n",
      "         [[0.2541]]]])\n",
      "Parameter containing:\n",
      "tensor([[[[-0.2220, -0.0462, -0.1132],\n",
      "          [-0.0629, -0.2082,  0.0946],\n",
      "          [-0.2113, -0.0150,  0.0819]],\n",
      "\n",
      "         [[-0.0794,  0.1337,  0.0297],\n",
      "          [ 0.1296,  0.1512, -0.1041],\n",
      "          [ 0.0857, -0.1020,  0.0739]]],\n",
      "\n",
      "\n",
      "        [[[-0.1232,  0.1090,  0.0477],\n",
      "          [-0.0922, -0.1156,  0.0610],\n",
      "          [ 0.2199,  0.1131, -0.0228]],\n",
      "\n",
      "         [[-0.0114,  0.1340, -0.1638],\n",
      "          [ 0.0784, -0.0781,  0.1364],\n",
      "          [-0.0841,  0.0117,  0.0796]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1620, -0.0346,  0.2150],\n",
      "          [-0.1994, -0.0420, -0.2350],\n",
      "          [ 0.0195,  0.0669, -0.0954]],\n",
      "\n",
      "         [[ 0.0979, -0.0382, -0.2048],\n",
      "          [ 0.1810,  0.1453,  0.1192],\n",
      "          [ 0.1880,  0.0867,  0.1253]]]], requires_grad=True)\n",
      "tensor([[[[-0.5155]],\n",
      "\n",
      "         [[ 0.2212]],\n",
      "\n",
      "         [[ 0.1487]]]], grad_fn=<AddBackward0>)\n",
      "tensor([[[[0.0036]],\n",
      "\n",
      "         [[0.0477]],\n",
      "\n",
      "         [[0.1622]]]], grad_fn=<AddBackward0>)\n",
      "tensor([[[[-0.5155]],\n",
      "\n",
      "         [[ 0.2212]],\n",
      "\n",
      "         [[ 0.1487]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0036]],\n",
      "\n",
      "         [[ 0.0477]],\n",
      "\n",
      "         [[ 0.1622]]]], grad_fn=<SlowConv2DBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "convlayer = nn.Conv2d(2, 3, 3, padding=(1,1), padding_mode='circular', bias=False)\n",
    "\n",
    "input = torch.rand(2, 2, 1, 1)\n",
    "\n",
    "padded_input = F.pad(input, convlayer._reversed_padding_repeated_twice, mode=convlayer.padding_mode)\n",
    "output = F.conv2d(padded_input, convlayer.weight, convlayer.bias, convlayer.stride, torch.nn.modules.utils._pair(0), convlayer.dilation, convlayer.groups)\n",
    "\n",
    "output11 = F.conv2d(padded_input[0:1,0:1,:,:], convlayer.weight[:,0:1,:,:], convlayer.bias, convlayer.stride, torch.nn.modules.utils._pair(0), convlayer.dilation, convlayer.groups)\n",
    "output12 = F.conv2d(padded_input[0:1,1:2,:,:], convlayer.weight[:,1:2,:,:], convlayer.bias, convlayer.stride, torch.nn.modules.utils._pair(0), convlayer.dilation, convlayer.groups)\n",
    "\n",
    "output21 = F.conv2d(padded_input[1:2,0:1,:,:], convlayer.weight[:,0:1,:,:], convlayer.bias, convlayer.stride, torch.nn.modules.utils._pair(0), convlayer.dilation, convlayer.groups)\n",
    "output22 = F.conv2d(padded_input[1:2,1:2,:,:], convlayer.weight[:,1:2,:,:], convlayer.bias, convlayer.stride, torch.nn.modules.utils._pair(0), convlayer.dilation, convlayer.groups)\n",
    "\n",
    "print(input)\n",
    "\n",
    "print(convlayer.weight)\n",
    "\n",
    "print(output11 + output12)\n",
    "print(output21 + output22)\n",
    "print(convlayer(input))\n",
    "\n",
    "# print(convlayer.weight)\n",
    "# print(convlayer.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.6426, grad_fn=<MulBackward0>)\n",
      "tensor(0.1802, grad_fn=<MulBackward0>)\n",
      "tensor(-0.1309, grad_fn=<MulBackward0>)\n",
      "tensor(0.1271, grad_fn=<MulBackward0>)\n",
      "tensor(0.0409, grad_fn=<MulBackward0>)\n",
      "tensor(0.2796, grad_fn=<MulBackward0>)\n",
      "batch next\n",
      "tensor(-0.0773, grad_fn=<MulBackward0>)\n",
      "tensor(0.0217, grad_fn=<MulBackward0>)\n",
      "tensor(-0.0157, grad_fn=<MulBackward0>)\n",
      "tensor(0.0809, grad_fn=<MulBackward0>)\n",
      "tensor(0.0260, grad_fn=<MulBackward0>)\n",
      "tensor(0.1780, grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(convlayer.weight[0,0,:,:].sum() * 0.9149)\n",
    "print(convlayer.weight[1,0,:,:].sum() * 0.9149)\n",
    "print(convlayer.weight[2,0,:,:].sum() * 0.9149)\n",
    "\n",
    "print(convlayer.weight[0,1,:,:].sum() * 0.3993)\n",
    "print(convlayer.weight[1,1,:,:].sum() * 0.3993)\n",
    "print(convlayer.weight[2,1,:,:].sum() * 0.3993)\n",
    "\n",
    "\n",
    "print('batch next')\n",
    "print(convlayer.weight[0,0,:,:].sum() * 0.1100)\n",
    "print(convlayer.weight[1,0,:,:].sum() * 0.1100)\n",
    "print(convlayer.weight[2,0,:,:].sum() * 0.1100)\n",
    "\n",
    "print(convlayer.weight[0,1,:,:].sum() * 0.2541)\n",
    "print(convlayer.weight[1,1,:,:].sum() * 0.2541)\n",
    "print(convlayer.weight[2,1,:,:].sum() * 0.2541)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.6426]],\n",
      "\n",
      "         [[ 0.1802]],\n",
      "\n",
      "         [[-0.1310]]]], grad_fn=<MulBackward0>)\n",
      "tensor([[[[0.1271]],\n",
      "\n",
      "         [[0.0409]],\n",
      "\n",
      "         [[0.2796]]]], grad_fn=<MulBackward0>)\n",
      "batch next\n",
      "tensor([[[[-0.0773]],\n",
      "\n",
      "         [[ 0.0217]],\n",
      "\n",
      "         [[-0.0158]]]], grad_fn=<SlowConv2DBackward0>)\n",
      "tensor([[[[0.0809]],\n",
      "\n",
      "         [[0.0260]],\n",
      "\n",
      "         [[0.1780]]]], grad_fn=<SlowConv2DBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "convlayer = nn.Conv2d(2, 3, 3, padding=(1,1), padding_mode='circular', bias=False)\n",
    "\n",
    "input = torch.rand(2, 2, 1, 1)\n",
    "\n",
    "padded_input = F.pad(input, convlayer._reversed_padding_repeated_twice, mode=convlayer.padding_mode)\n",
    "output = F.conv2d(padded_input, convlayer.weight, convlayer.bias, convlayer.stride, torch.nn.modules.utils._pair(0), convlayer.dilation, convlayer.groups)\n",
    "\n",
    "output11 = F.conv2d(padded_input[0:1,0:1,:,:], convlayer.weight[:,0:1,:,:], convlayer.bias, convlayer.stride, torch.nn.modules.utils._pair(0), convlayer.dilation, convlayer.groups)\n",
    "output12 = F.conv2d(padded_input[0:1,1:2,:,:], convlayer.weight[:,1:2,:,:], convlayer.bias, convlayer.stride, torch.nn.modules.utils._pair(0), convlayer.dilation, convlayer.groups)\n",
    "\n",
    "output21 = F.conv2d(padded_input[1:2,0:1,:,:], convlayer.weight[:,0:1,:,:], convlayer.bias, convlayer.stride, torch.nn.modules.utils._pair(0), convlayer.dilation, convlayer.groups)\n",
    "output22 = F.conv2d(padded_input[1:2,1:2,:,:], convlayer.weight[:,1:2,:,:], convlayer.bias, convlayer.stride, torch.nn.modules.utils._pair(0), convlayer.dilation, convlayer.groups)\n",
    "\n",
    "# print(input)\n",
    "\n",
    "# print(convlayer.weight)\n",
    "\n",
    "print(output11 * 1)\n",
    "print(output12 * 1)\n",
    "\n",
    "print('batch next')\n",
    "print(output21)\n",
    "print(output22)\n",
    "\n",
    "# print(convlayer(input))\n",
    "\n",
    "# print(convlayer.weight)\n",
    "# print(convlayer.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('pytorch-devel')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "746d1c1fe05b765ee7ecaa8b421be9fa4f6134b00b1cddd46be87e0084c0c9b9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
