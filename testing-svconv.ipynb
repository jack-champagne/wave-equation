{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.  ]\n",
      "  [0.   1.   0.   0.67 0.  ]\n",
      "  [0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.  ]]\n",
      "\n",
      " [[1.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.67 0.   1.   0.  ]\n",
      "  [0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.  ]]]\n"
     ]
    }
   ],
   "source": [
    "input_shape = (1, 5, 5)\n",
    "spatial_scalars = np.zeros([2, 5, 5])\n",
    "spatial_scalars[0][0][0] = 1\n",
    "spatial_scalars[0][2][1] = 1\n",
    "spatial_scalars[0][2][3] = 0.67\n",
    "spatial_scalars[1][0][0] = 1\n",
    "spatial_scalars[1][2][1] = 0.67\n",
    "spatial_scalars[1][2][3] = 1\n",
    "print(spatial_scalars)\n",
    "input = np.array([\n",
    "    [[0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "     [0.6, 0.9, 0.6, 0.9, 0.6],\n",
    "     [0.9, 0.0, 0.9, 0.0, 0.9],\n",
    "     [0.6, 0.9, 0.6, 0.9, 0.6],\n",
    "     [0.1, 0.2, 0.3, 0.4, 0.5]]\n",
    "    ])\n",
    "filters = np.random.random((2, 3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spatial_scalars:\n",
      " [[[1.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.  ]\n",
      "  [0.   1.   0.   0.67 0.  ]\n",
      "  [0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.  ]]\n",
      "\n",
      " [[1.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.67 0.   1.   0.  ]\n",
      "  [0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.  ]]]\n",
      "input:\n",
      " [[[0.1 0.2 0.3 0.4 0.5]\n",
      "  [0.6 0.9 0.6 0.9 0.6]\n",
      "  [0.9 0.  0.9 0.  0.9]\n",
      "  [0.6 0.9 0.6 0.9 0.6]\n",
      "  [0.1 0.2 0.3 0.4 0.5]]]\n",
      "convolutional filters:\n",
      " [[[0.27682014 0.69281588 0.35439976]\n",
      "  [0.75888168 0.83444698 0.56203042]\n",
      "  [0.62499996 0.75537329 0.48024273]]\n",
      "\n",
      " [[0.86261401 0.93325164 0.95063944]\n",
      "  [0.78945347 0.44986295 0.7652076 ]\n",
      "  [0.25335811 0.83444987 0.13714965]]]\n"
     ]
    }
   ],
   "source": [
    "print(\"spatial_scalars:\\n\", spatial_scalars)\n",
    "print(\"input:\\n\", input)\n",
    "print(\"convolutional filters:\\n\", filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:\n",
      " [[[0.1 0.2 0.3 0.4 0.5]\n",
      "  [0.6 0.9 0.6 0.9 0.6]\n",
      "  [0.9 0.  0.9 0.  0.9]\n",
      "  [0.6 0.9 0.6 0.9 0.6]\n",
      "  [0.1 0.2 0.3 0.4 0.5]]]\n",
      "after:\n",
      " [[[[2.11430564 0.         0.         0.         0.        ]\n",
      "   [0.         0.         0.         0.         0.        ]\n",
      "   [0.         3.53406869 0.         2.36782602 0.        ]\n",
      "   [0.         0.         0.         0.         0.        ]\n",
      "   [0.         0.         0.         0.         0.        ]]]\n",
      "\n",
      "\n",
      " [[[2.08363408 0.         0.         0.         0.        ]\n",
      "   [0.         0.         0.         0.         0.        ]\n",
      "   [0.         2.88929665 0.         4.31238305 0.        ]\n",
      "   [0.         0.         0.         0.         0.        ]\n",
      "   [0.         0.         0.         0.         0.        ]]]]\n"
     ]
    }
   ],
   "source": [
    "# Simply applies convolutional filter and returns the inner product\n",
    "def filter_pass(domain, x, y, filter):\n",
    "    acc = 0 # bias put here as a f(filter, x, y)\n",
    "    offset = (filter.shape[1]//2) # assume conv filters are square\n",
    "    for dx in range(-offset, offset + 1):\n",
    "        for dy in range(-offset, offset + 1):\n",
    "            acc += domain[0][(x + dx) % domain.shape[1]][(y + dy) % domain.shape[2]] * filter[dx + offset][dy + offset]\n",
    "    return acc\n",
    "\n",
    "\n",
    "## Spatially variant scalar convolution operation, wrap around, no bias\n",
    "def svconv2d_filter(input, filter, spatial_scalars):\n",
    "    ret = np.empty(shape=input.shape)\n",
    "    for x in range(input.shape[1]):\n",
    "        for y in range(input.shape[2]):\n",
    "            # 0 here for now because we only are trying this out on 1 channel, will iterate over all channels when time comes.\n",
    "            ret[0][x][y] = spatial_scalars[x][y] * filter_pass(input, x, y, filter)\n",
    "    return ret\n",
    "\n",
    "def svconv2d(input, filters, spatial_scalars):\n",
    "    return np.array([svconv2d_filter(input, filter=filters[i], spatial_scalars=spatial_scalars[i]) for i in range(filters.shape[0])])\n",
    "\n",
    "# after = svconv2d_filter(input, filters[0], spatial_scalars[0])\n",
    "print('input:\\n', input)\n",
    "print('after:\\n', svconv2d(input, filters, spatial_scalars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6700000006575954"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.83395446/2.73724546"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 28, 28])\n",
      "torch.Size([1, 2, 30, 30])\n"
     ]
    }
   ],
   "source": [
    "## Circular padding:\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "input = torch.ones((1, 2, 28, 28))\n",
    "print(input.shape)\n",
    "print(F.pad(input, (1,1,1,1),\"circular\").shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1.6960, 2.8627, 2.7872],\n",
      "          [2.5623, 2.8967, 1.8286],\n",
      "          [2.6685, 1.9926, 2.4295]]]])\n",
      "tensor([[[[1.8990, 1.8309, 2.0206],\n",
      "          [1.5767, 1.8376, 2.2277],\n",
      "          [1.7805, 2.0700, 2.2526]]]])\n",
      "tensor([[[3.5949, 4.6936, 4.8078],\n",
      "         [4.1390, 4.7343, 4.0563],\n",
      "         [4.4490, 4.0626, 4.6821]]])\n",
      "tensor([[[[3.5949, 4.6936, 4.8078],\n",
      "          [4.1390, 4.7343, 4.0563],\n",
      "          [4.4490, 4.0626, 4.6821]]]])\n"
     ]
    }
   ],
   "source": [
    "inpt = torch.rand(1, 2, 3, 3)\n",
    "a = F.pad(inpt, (1, 1, 1, 1), mode='circular')\n",
    "conv = torch.rand(1, 2, 3, 3)\n",
    "\n",
    "spatial_scalars = torch.zeros(2, 3, 3)\n",
    "\n",
    "# print(F.conv2d(a, conv))\n",
    "\n",
    "output = torch.zeros(inpt.shape)\n",
    "for chan in range(a.shape[1]):\n",
    "    intermed = F.conv2d(a[:,chan:chan+1,:,:], conv[:,chan:chan+1,:,:])\n",
    "    print(intermed)\n",
    "    output[:,chan:chan+1,:,:] += 1 * intermed\n",
    "print(output[:,0,:,:] + output[:,1,:,:])\n",
    "print(F.conv2d(a, conv))\n",
    "assert not (torch.isclose(output[:,0,:,:] + output[:,1,:,:], F.conv2d(a, conv)).__contains__(False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[2, 2],\n",
      "          [8, 5]],\n",
      "\n",
      "         [[3, 8],\n",
      "          [1, 3]]]])\n",
      "tensor([[[[0., 0.],\n",
      "          [1., 0.]],\n",
      "\n",
      "         [[0., 0.],\n",
      "          [3., 0.]]]])\n",
      "tensor([[[ 0.,  0.],\n",
      "         [11.,  0.]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randint(0, 9, (1, 2, 2, 2))\n",
    "print(x)\n",
    "a = torch.zeros((1, 2, 2, 2))\n",
    "a[0][0][1][0] = 1\n",
    "a[0][1][1][0] = 3\n",
    "print(a)\n",
    "print((a * x).sum(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1, 1) + (2,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/jack/Repos/jack-champagne/p4m-wave-equation/scaled-spatial-conv/testing-svconv.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jack/Repos/jack-champagne/p4m-wave-equation/scaled-spatial-conv/testing-svconv.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrand(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m3\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jack/Repos/jack-champagne/p4m-wave-equation/scaled-spatial-conv/testing-svconv.ipynb#X12sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m convlayer \u001b[39m=\u001b[39m SVConv2d(in_channels\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, out_channels\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, kernel_size\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, spatial_scalar_hint\u001b[39m=\u001b[39m\u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize(), stride\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, padding\u001b[39m=\u001b[39m(\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m), padding_mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcircular\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/jack/Repos/jack-champagne/p4m-wave-equation/scaled-spatial-conv/testing-svconv.ipynb#X12sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m convlayer(\u001b[39minput\u001b[39;49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch-devel/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1103\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Repos/jack-champagne/p4m-wave-equation/scaled-spatial-conv/svconv.py:310\u001b[0m, in \u001b[0;36mSVConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 310\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mspatial_scalars, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/Repos/jack-champagne/p4m-wave-equation/scaled-spatial-conv/svconv.py:303\u001b[0m, in \u001b[0;36mSVConv2d._conv_forward\u001b[0;34m(self, input, weight, spatial_scalars, bias)\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[39mfor\u001b[39;00m chan \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(padded_input\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]):\n\u001b[1;32m    302\u001b[0m         chout \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mconv2d(padded_input[:,chan:chan\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m,:,:], weight[:,chan:chan\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m,:,:], bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride, _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 303\u001b[0m         output \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49maddcmul(output, chout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mspatial_scalars\u001b[39m.\u001b[39;49mT)\n\u001b[1;32m    304\u001b[0m     \u001b[39mreturn\u001b[39;00m output\n\u001b[1;32m    306\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(\u001b[39minput\u001b[39m, weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    307\u001b[0m                 \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 3"
     ]
    }
   ],
   "source": [
    "from svconv import SVConv2d\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "input = torch.rand(1, 2, 3, 3)\n",
    "\n",
    "convlayer = SVConv2d(in_channels=2, out_channels=2, kernel_size=3, spatial_scalar_hint=input.size(), stride=1, padding=(1,1), padding_mode='circular')\n",
    "convlayer(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.8436, 0.4265, 0.9561],\n",
      "          [0.0770, 0.4108, 0.0014],\n",
      "          [0.5414, 0.6419, 0.2976]],\n",
      "\n",
      "         [[0.7077, 0.4189, 0.0655],\n",
      "          [0.8839, 0.8083, 0.7528],\n",
      "          [0.8988, 0.6839, 0.7658]]],\n",
      "\n",
      "\n",
      "        [[[0.9149, 0.3993, 0.1100],\n",
      "          [0.2541, 0.4333, 0.4451],\n",
      "          [0.4966, 0.7865, 0.6604]],\n",
      "\n",
      "         [[0.1303, 0.3498, 0.3824],\n",
      "          [0.8043, 0.3186, 0.2908],\n",
      "          [0.4196, 0.3728, 0.3769]]]])\n",
      "Parameter containing:\n",
      "tensor([[[[-0.2220, -0.0462, -0.1132],\n",
      "          [-0.0629, -0.2082,  0.0946],\n",
      "          [-0.2113, -0.0150,  0.0819]],\n",
      "\n",
      "         [[-0.0794,  0.1337,  0.0297],\n",
      "          [ 0.1296,  0.1512, -0.1041],\n",
      "          [ 0.0857, -0.1020,  0.0739]]],\n",
      "\n",
      "\n",
      "        [[[-0.1232,  0.1090,  0.0477],\n",
      "          [-0.0922, -0.1156,  0.0610],\n",
      "          [ 0.2199,  0.1131, -0.0228]],\n",
      "\n",
      "         [[-0.0114,  0.1340, -0.1638],\n",
      "          [ 0.0784, -0.0781,  0.1364],\n",
      "          [-0.0841,  0.0117,  0.0796]]]], requires_grad=True)\n",
      "tensor([[[[-0.1413, -0.0174, -0.3211],\n",
      "          [-0.0218, -0.2812, -0.1790],\n",
      "          [-0.0900, -0.0589,  0.0687]],\n",
      "\n",
      "         [[-0.0891, -0.0054,  0.0525],\n",
      "          [ 0.2488,  0.2581,  0.2572],\n",
      "          [ 0.3695,  0.1883,  0.1604]]]], grad_fn=<AddBackward0>)\n",
      "tensor([[[[-0.4441, -0.2598, -0.1204],\n",
      "          [-0.0938, -0.1651, -0.3753],\n",
      "          [-0.0217, -0.3870, -0.1969]],\n",
      "\n",
      "         [[ 0.1041,  0.0047,  0.1783],\n",
      "          [ 0.2068,  0.1325,  0.3112],\n",
      "          [ 0.1389,  0.2491, -0.0859]]]], grad_fn=<AddBackward0>)\n",
      "tensor([[[[-0.1413, -0.0174, -0.3211],\n",
      "          [-0.0218, -0.2812, -0.1790],\n",
      "          [-0.0900, -0.0589,  0.0687]],\n",
      "\n",
      "         [[-0.0891, -0.0054,  0.0525],\n",
      "          [ 0.2488,  0.2581,  0.2572],\n",
      "          [ 0.3695,  0.1883,  0.1604]]],\n",
      "\n",
      "\n",
      "        [[[-0.4441, -0.2598, -0.1204],\n",
      "          [-0.0938, -0.1651, -0.3753],\n",
      "          [-0.0217, -0.3870, -0.1969]],\n",
      "\n",
      "         [[ 0.1041,  0.0047,  0.1783],\n",
      "          [ 0.2068,  0.1325,  0.3112],\n",
      "          [ 0.1389,  0.2491, -0.0859]]]], grad_fn=<SlowConv2DBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "convlayer = nn.Conv2d(2, 2, 3, padding=(1,1), padding_mode='circular', bias=False)\n",
    "\n",
    "input = torch.rand(2, 2, 3, 3)\n",
    "\n",
    "padded_input = F.pad(input, convlayer._reversed_padding_repeated_twice, mode=convlayer.padding_mode)\n",
    "output = F.conv2d(padded_input, convlayer.weight, convlayer.bias, convlayer.stride, torch.nn.modules.utils._pair(0), convlayer.dilation, convlayer.groups)\n",
    "\n",
    "output11 = F.conv2d(padded_input[0:1,0:1,:,:], convlayer.weight[:,0:1,:,:], convlayer.bias, convlayer.stride, torch.nn.modules.utils._pair(0), convlayer.dilation, convlayer.groups)\n",
    "output12 = F.conv2d(padded_input[0:1,1:2,:,:], convlayer.weight[:,1:2,:,:], convlayer.bias, convlayer.stride, torch.nn.modules.utils._pair(0), convlayer.dilation, convlayer.groups)\n",
    "\n",
    "output21 = F.conv2d(padded_input[1:2,0:1,:,:], convlayer.weight[:,0:1,:,:], convlayer.bias, convlayer.stride, torch.nn.modules.utils._pair(0), convlayer.dilation, convlayer.groups)\n",
    "output22 = F.conv2d(padded_input[1:2,1:2,:,:], convlayer.weight[:,1:2,:,:], convlayer.bias, convlayer.stride, torch.nn.modules.utils._pair(0), convlayer.dilation, convlayer.groups)\n",
    "\n",
    "print(input)\n",
    "\n",
    "print(convlayer.weight)\n",
    "\n",
    "print(output11 + output12)\n",
    "print(output21 + output22)\n",
    "print(convlayer(input))\n",
    "\n",
    "# print(convlayer.weight)\n",
    "# print(convlayer.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.2976, 0.5414, 0.6419, 0.2976, 0.5414],\n",
      "          [0.9561, 0.8436, 0.4265, 0.9561, 0.8436],\n",
      "          [0.0014, 0.0770, 0.4108, 0.0014, 0.0770],\n",
      "          [0.2976, 0.5414, 0.6419, 0.2976, 0.5414],\n",
      "          [0.9561, 0.8436, 0.4265, 0.9561, 0.8436]],\n",
      "\n",
      "         [[0.7658, 0.8988, 0.6839, 0.7658, 0.8988],\n",
      "          [0.0655, 0.7077, 0.4189, 0.0655, 0.7077],\n",
      "          [0.7528, 0.8839, 0.8083, 0.7528, 0.8839],\n",
      "          [0.7658, 0.8988, 0.6839, 0.7658, 0.8988],\n",
      "          [0.0655, 0.7077, 0.4189, 0.0655, 0.7077]]],\n",
      "\n",
      "\n",
      "        [[[0.6604, 0.4966, 0.7865, 0.6604, 0.4966],\n",
      "          [0.1100, 0.9149, 0.3993, 0.1100, 0.9149],\n",
      "          [0.4451, 0.2541, 0.4333, 0.4451, 0.2541],\n",
      "          [0.6604, 0.4966, 0.7865, 0.6604, 0.4966],\n",
      "          [0.1100, 0.9149, 0.3993, 0.1100, 0.9149]],\n",
      "\n",
      "         [[0.3769, 0.4196, 0.3728, 0.3769, 0.4196],\n",
      "          [0.3824, 0.1303, 0.3498, 0.3824, 0.1303],\n",
      "          [0.2908, 0.8043, 0.3186, 0.2908, 0.8043],\n",
      "          [0.3769, 0.4196, 0.3728, 0.3769, 0.4196],\n",
      "          [0.3824, 0.1303, 0.3498, 0.3824, 0.1303]]]])\n"
     ]
    }
   ],
   "source": [
    "print(padded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor, tensor\n",
    "\n",
    "def compute_cross_corr(t1: Tensor, t2: Tensor):\n",
    "    assert t1.numel() == t2.numel(), \"{} {} dimension do not match\".format(t1.shape, t2.shape)\n",
    "    a = torch.mul(t1, t2)\n",
    "    return torch.sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.3270, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_cross_corr(padded_input[0:1,0:1,0:3,0:3], convlayer.weight[0:1,0:1,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.5070, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(compute_cross_corr(padded_input[0:1,1:2,0:3,0:3], convlayer.weight[0:1,0:1,:,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.7658, 0.8988, 0.6839],\n",
       "          [0.0655, 0.7077, 0.4189],\n",
       "          [0.7528, 0.8839, 0.8083]]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-0.1070\n",
    "padded_input[0:1,1:2,0:3,0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[-0.2220, -0.0462, -0.1132],\n",
      "          [-0.0629, -0.2082,  0.0946],\n",
      "          [-0.2113, -0.0150,  0.0819]],\n",
      "\n",
      "         [[-0.0794,  0.1337,  0.0297],\n",
      "          [ 0.1296,  0.1512, -0.1041],\n",
      "          [ 0.0857, -0.1020,  0.0739]]],\n",
      "\n",
      "\n",
      "        [[[-0.1232,  0.1090,  0.0477],\n",
      "          [-0.0922, -0.1156,  0.0610],\n",
      "          [ 0.2199,  0.1131, -0.0228]],\n",
      "\n",
      "         [[-0.0114,  0.1340, -0.1638],\n",
      "          [ 0.0784, -0.0781,  0.1364],\n",
      "          [-0.0841,  0.0117,  0.0796]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1620, -0.0346,  0.2150],\n",
      "          [-0.1994, -0.0420, -0.2350],\n",
      "          [ 0.0195,  0.0669, -0.0954]],\n",
      "\n",
      "         [[ 0.0979, -0.0382, -0.2048],\n",
      "          [ 0.1810,  0.1453,  0.1192],\n",
      "          [ 0.1880,  0.0867,  0.1253]]]], requires_grad=True)\n",
      "tensor([[[[-0.5155]],\n",
      "\n",
      "         [[ 0.2212]],\n",
      "\n",
      "         [[ 0.1487]]]], grad_fn=<AddBackward0>)\n",
      "tensor([[[[-0.5155]],\n",
      "\n",
      "         [[ 0.2212]],\n",
      "\n",
      "         [[ 0.1487]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0036]],\n",
      "\n",
      "         [[ 0.0477]],\n",
      "\n",
      "         [[ 0.1622]]]], grad_fn=<SlowConv2DBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "convlayer = nn.Conv2d(2, 3, 3, padding=(1,1), padding_mode='circular', bias=False)\n",
    "\n",
    "input = torch.rand(2, 2, 1, 1)\n",
    "\n",
    "padded_input = F.pad(input, convlayer._reversed_padding_repeated_twice, mode=convlayer.padding_mode)\n",
    "output = F.conv2d(padded_input, convlayer.weight, convlayer.bias, convlayer.stride, torch.nn.modules.utils._pair(0), convlayer.dilation, convlayer.groups)\n",
    "\n",
    "output11 = F.conv2d(padded_input[0:1,0:1,:,:], convlayer.weight[:,0:1,:,:], convlayer.bias, convlayer.stride, torch.nn.modules.utils._pair(0), convlayer.dilation, convlayer.groups)\n",
    "output12 = F.conv2d(padded_input[0:1,1:2,:,:], convlayer.weight[:,1:2,:,:], convlayer.bias, convlayer.stride, torch.nn.modules.utils._pair(0), convlayer.dilation, convlayer.groups)\n",
    "\n",
    "print(convlayer.weight)\n",
    "\n",
    "print(output11 + output12)\n",
    "print(convlayer(input))\n",
    "\n",
    "# print(convlayer.weight)\n",
    "# print(convlayer.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.6426, grad_fn=<MulBackward0>)\n",
      "tensor(0.1802, grad_fn=<MulBackward0>)\n",
      "tensor(-0.1309, grad_fn=<MulBackward0>)\n",
      "tensor(0.1271, grad_fn=<MulBackward0>)\n",
      "tensor(0.0409, grad_fn=<MulBackward0>)\n",
      "tensor(0.2796, grad_fn=<MulBackward0>)\n",
      "batch next\n",
      "tensor(-0.0773, grad_fn=<MulBackward0>)\n",
      "tensor(0.0217, grad_fn=<MulBackward0>)\n",
      "tensor(-0.0157, grad_fn=<MulBackward0>)\n",
      "tensor(0.0809, grad_fn=<MulBackward0>)\n",
      "tensor(0.0260, grad_fn=<MulBackward0>)\n",
      "tensor(0.1780, grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(convlayer.weight[0,0,:,:].sum() * 0.9149)\n",
    "print(convlayer.weight[1,0,:,:].sum() * 0.9149)\n",
    "print(convlayer.weight[2,0,:,:].sum() * 0.9149)\n",
    "\n",
    "print(convlayer.weight[0,1,:,:].sum() * 0.3993)\n",
    "print(convlayer.weight[1,1,:,:].sum() * 0.3993)\n",
    "print(convlayer.weight[2,1,:,:].sum() * 0.3993)\n",
    "\n",
    "\n",
    "print('batch next')\n",
    "print(convlayer.weight[0,0,:,:].sum() * 0.1100)\n",
    "print(convlayer.weight[1,0,:,:].sum() * 0.1100)\n",
    "print(convlayer.weight[2,0,:,:].sum() * 0.1100)\n",
    "\n",
    "print(convlayer.weight[0,1,:,:].sum() * 0.2541)\n",
    "print(convlayer.weight[1,1,:,:].sum() * 0.2541)\n",
    "print(convlayer.weight[2,1,:,:].sum() * 0.2541)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.9149]],\n",
      "\n",
      "         [[0.3993]]],\n",
      "\n",
      "\n",
      "        [[[0.1100]],\n",
      "\n",
      "         [[0.2541]]]])\n",
      "tensor([[[[-0.6426]],\n",
      "\n",
      "         [[ 0.1802]],\n",
      "\n",
      "         [[-0.1310]]],\n",
      "\n",
      "\n",
      "        [[[-0.0773]],\n",
      "\n",
      "         [[ 0.0217]],\n",
      "\n",
      "         [[-0.0158]]]], grad_fn=<SlowConv2DBackward0>)\n",
      "tensor([[[[0.1271]],\n",
      "\n",
      "         [[0.0409]],\n",
      "\n",
      "         [[0.2796]]],\n",
      "\n",
      "\n",
      "        [[[0.0809]],\n",
      "\n",
      "         [[0.0260]],\n",
      "\n",
      "         [[0.1780]]]], grad_fn=<SlowConv2DBackward0>)\n",
      "tensor([[[[-1.4123]],\n",
      "\n",
      "         [[ 0.3195]],\n",
      "\n",
      "         [[-0.5415]]],\n",
      "\n",
      "\n",
      "        [[[-0.2355]],\n",
      "\n",
      "         [[ 0.0173]],\n",
      "\n",
      "         [[-0.2095]]]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "convlayer = nn.Conv2d(2, 3, 3, padding=(1,1), padding_mode='circular', bias=False)\n",
    "\n",
    "input = torch.rand(2, 2, 1, 1)\n",
    "\n",
    "padded_input = F.pad(input, convlayer._reversed_padding_repeated_twice, mode=convlayer.padding_mode)\n",
    "output = F.conv2d(padded_input, convlayer.weight, convlayer.bias, convlayer.stride, torch.nn.modules.utils._pair(0), convlayer.dilation, convlayer.groups)\n",
    "\n",
    "output11 = F.conv2d(padded_input[:,0:1,:,:], convlayer.weight[:,0:1,:,:], convlayer.bias, convlayer.stride, torch.nn.modules.utils._pair(0), convlayer.dilation, convlayer.groups)\n",
    "output12 = F.conv2d(padded_input[:,1:2,:,:], convlayer.weight[:,1:2,:,:], convlayer.bias, convlayer.stride, torch.nn.modules.utils._pair(0), convlayer.dilation, convlayer.groups)\n",
    "\n",
    "print(input)\n",
    "print(output11)\n",
    "print(output12)\n",
    "print(output11 * 2 + output12 * -1)\n",
    "assert torch.allclose(output11 * 1 + output12 * 1, convlayer(input)), \"ERROR!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.3728]],\n",
      "\n",
      "         [[0.3769]]],\n",
      "\n",
      "\n",
      "        [[[0.0108]],\n",
      "\n",
      "         [[0.9455]]]])\n",
      "tensor([[[[2.]],\n",
      "\n",
      "         [[2.]]],\n",
      "\n",
      "\n",
      "        [[[2.]],\n",
      "\n",
      "         [[2.]]]])\n",
      "tensor([[[[0.7456]],\n",
      "\n",
      "         [[0.7538]]],\n",
      "\n",
      "\n",
      "        [[[0.0216]],\n",
      "\n",
      "         [[1.8910]]]])\n"
     ]
    }
   ],
   "source": [
    "input = torch.rand(2, 2, 1, 1)\n",
    "sones = 2 * torch.ones(2, 2, 1, 1)\n",
    "print(input)\n",
    "print(sones)\n",
    "print(torch.addcmul(torch.zeros(2, 2, 1, 1), input, sones))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('pytorch-devel')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "746d1c1fe05b765ee7ecaa8b421be9fa4f6134b00b1cddd46be87e0084c0c9b9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
